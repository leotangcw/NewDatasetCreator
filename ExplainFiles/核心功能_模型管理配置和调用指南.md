
# 核心功能_模型管理配置和调用指南

> **版本**: 0.2 beta  
**作者**: leotcw&AI
> **模块**: `src/model_manager.py`（模型管理模块）  
> **最后更新**: 2025-11-15  
> **对应设计文档**: `DesignFiles/核心功能_模型管理配置和调用指南.md`

## 目录

1. [模块概述](#1-模块概述)
2. [环境与依赖](#2-环境与依赖)
3. [核心数据结构与配置](#3-核心数据结构与配置)
4. [Python 调用方式](#4-python-调用方式)
5. [命令行用法](#5-命令行用法)
6. [配置文件结构要点](#6-配置文件结构要点)
7. [常见问题与排查](#7-常见问题与排查)

---

## 1. 模块概述

`model_manager.py` 负责统一管理自动数据蒸馏软件中可用的推理后端模型，主要能力包括：

- 管理多种模型类型（vLLM、OpenAI、SGlang、Ollama 等）的配置；
- 提供模型配置的增删改查接口；
- 提供连接性测试和状态更新功能；
- 输出按模型类型和状态统计的汇总信息；
- 提供统一的 `generate_text` 文本生成接口。

模块本身不负责任务调度和前端 UI，只提供面向其他 Python 模块或 CLI 的服务。

---

## 2. 环境与依赖

### 2.1 安装依赖

在项目根目录执行：

```bash
pip install -r requirements.txt
```

模型管理模块依赖 `requests` 以及基础支撑层提供的 `config_manager`、`log_manager`、`utils.SecurityUtils` 等，这些都已包含在项目依赖中。

### 2.2 与基础支撑层的关系

- 通过 `config_manager` 读取/更新配置（包括 `model.supported_types`、`model.default_timeout`、`download.encrypt_api_key` 和 `models` 节点）；
- 通过 `log_manager` 记录模型增删改查和测试日志；
- 通过 `SecurityUtils` 对 API Key 进行加解密；
- 通过 `NetworkUtils` 等工具封装网络相关操作（若源码中使用）。

---

## 3. 核心数据结构与配置

### 3.1 支持的模型类型

源码中通过 `ModelType` 枚举和配置项 `model.supported_types` 共同约束支持的类型：

- `vllm`
- `openai`
- `sglang`
- `ollama`

是否支持具体类型，以 `config.yaml` 中 `model.supported_types` 实际配置为准。

### 3.2 模型配置结构

模型配置存放于 `config.yaml` 的 `models` 节点，由 `add_model` 写入，`get_model_config/get_all_models` 读取。单个模型大致结构示例：

```yaml
models:
  example-model:
    type: "openai"           # 模型类型
    url: "https://api.example.com"  # 基础 API 地址
    api_key: "encrypted:..." # API 密钥（可能被加密）
    model_name: "gpt-4"      # 后端具体模型名（可选）
    timeout: 600              # 超时时间（秒）
    custom_headers: {}        # 自定义请求头
    status: "unknown"        # 最近一次测试状态
    last_test_time: ""       # 最近测试时间
    response_time: 0          # 最近测试响应时间（毫秒）
    error_msg: ""            # 最近错误信息
    created_time: "..."      # 创建时间
```

实际字段以 `ModelManager.add_model`、`_update_model_status` 等函数的实现为准。

### 3.3 API Key 加密存储约定

- 当 `download.encrypt_api_key` 为 `True` 时，`add_model/update_model` 会调用 `SecurityUtils.encrypt_text` 对 API Key 加密，并以 `encrypted:<密文>` 形式存储；
- `get_model_config` 会在返回给调用方前尝试解密，如解密失败则返回空字符串；
- `get_all_models` 为避免泄露密钥，会将有值的 `api_key` 统一替换为占位文本，例如 `***encrypted***` 或 `***hidden***`。

---

## 4. Python 调用方式

### 4.1 获取全局模型管理器

```python
from src.model_manager import model_manager
```

模块底部创建了一个全局实例 `model_manager = ModelManager()`，一般直接使用该实例即可，无需手动构造。

### 4.2 添加模型

```python
from src.model_manager import model_manager

openai_config = {
    "name": "openai-gpt4",
    "type": "openai",
    "url": "https://api.openai.com",  # 或 OpenAI 兼容代理根地址
    "api_key": "sk-your-api-key",    # 必填
    "model_name": "gpt-4",           # 可选，作为后端模型名
    "timeout": 600,
}

ok = model_manager.add_model(openai_config)
print("添加结果:", ok)
```

> 必填字段仅为 `name/type/url`，但对于 OpenAI 类型，源码中会强制要求提供 `api_key`。

### 4.3 更新/删除模型

```python
# 更新（只更新被允许的字段）
updates = {
    "timeout": 900,
    "api_key": "new-api-key",  # 会按当前配置决定是否加密
}
ok = model_manager.update_model("openai-gpt4", updates)

# 删除模型
deleted = model_manager.delete_model("openai-gpt4")
```

更新时仅允许修改 `url/timeout/model_name/custom_headers/api_key` 等字段，具体可见 `update_model` 函数内部判断逻辑。

### 4.4 测试模型连接

```python
result = model_manager.test_model("openai-gpt4")
if result["success"]:
    print("在线，响应时间(ms):", result["response_time"])
else:
    print("测试失败:", result["error_msg"])

all_results = model_manager.test_all_models()
for name, r in all_results.items():
    print(name, "=>", "在线" if r["success"] else "离线", r.get("error_msg", ""))
```

`test_model/test_all_models` 会调用内部的 `_test_vllm_connection/_test_openai_connection/_test_sglang_connection/_test_ollama_connection` 等函数，并同步更新配置中的 `status/last_test_time/response_time/error_msg` 字段。

### 4.5 统计与列表查询

```python
all_models = model_manager.get_all_models()
active_models = model_manager.get_active_models()
stats = model_manager.get_model_statistics()

print("总模型数:", stats["total_models"])
print("在线模型:", stats["online_models"])
print("平均响应时间(ms):", stats["average_response_time"])
```

`get_all_models` 返回的是“脱敏后”的配置视图，不包含可用的明文 API Key。

### 4.6 统一文本生成接口

```python
from src.model_manager import model_manager

resp = model_manager.generate_text(
    model_name="openai-gpt4",   # 在配置中注册的模型名
    prompt="你好，简要介绍一下这个项目。",
    params={
        "max_tokens": 256,
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 50,  # 个别后端支持
    },
)

if resp.get("success"):
    print("生成内容:\n", resp["content"])
else:
    print("生成失败:", resp.get("error"))
```

`generate_text` 会根据模型类型选择不同实现分支：

- `openai`: 使用 `/v1/chat/completions` 风格接口；
- `vllm`: 调用 `/generate`；
- `sglang`: 调用 `/generate`，使用 `sampling_params`；
- `ollama`: 调用 `/api/generate`。

实际请求 URL 和参数构造逻辑请以源码实现为准。

---

## 5. 命令行用法

模块在 `if __name__ == "__main__":` 中提供了一个简单 CLI，支持 `add/test/list/delete/stats` 五类子命令。

进入项目根目录后可通过：

```bash
python src/model_manager.py --help
```

查看完整参数说明。典型调用示例：

### 5.1 添加模型

```bash
python src/model_manager.py add \
  --name openai-gpt4 \
  --type openai \
  --url https://api.openai.com \
  --api-key sk-your-key \
  --model-name gpt-4 \
  --timeout 600
```

### 5.2 测试模型

```bash
# 测试指定模型
python src/model_manager.py test --name openai-gpt4

# 测试全部模型
python src/model_manager.py test
```

### 5.3 列表/删除/统计

```bash
# 列出所有模型
python src/model_manager.py list

# 仅列出在线模型
python src/model_manager.py list --active-only

# 删除模型
python src/model_manager.py delete --name old-model

# 查看统计信息
python src/model_manager.py stats
```

---

## 6. 配置文件结构要点

与模型管理相关的配置主要分三部分：

1. `model` 段：控制默认超时、支持类型等通用参数；
2. `download.encrypt_api_key`：控制是否对 API Key 进行加密存储；
3. `models` 段：具体每个模型的配置，由 `ModelManager` 管理。

示例（仅为说明结构，具体值以实际配置为准）：

```yaml
model:
  default_timeout: 600
  supported_types: ["vllm", "openai", "sglang", "ollama"]

download:
  encrypt_api_key: true

models:
  # 由 model_manager.add_model() 维护
  # ...
```

配置的读写由 `config_manager` 负责，模型管理模块不会直接操作配置文件路径。

---

## 7. 常见问题与排查

### 7.1 添加模型失败

- 检查 `type` 是否在 `model.supported_types` 中；
- 检查是否缺少必填字段 `name/type/url`；
- 对于 `openai` 类型，确认已提供 `api_key`；
- 查看日志中 `添加模型失败` 相关记录，获取具体错误原因。

### 7.2 测试模型始终失败

- 确认基础 URL 填写的是正确的服务根地址或已包含完整路径；
- 检查网络连通性、防火墙或代理设置；
- 对 OpenAI 兼容服务，注意是否需要自定义 `model_name`、是否使用了正确的 `/v1/chat/completions` 风格接口；
- 对本地 vLLM/SGlang/Ollama，检查进程是否正常运行、端口是否正确。

### 7.3 API Key 相关问题

- 若配置中存储为 `encrypted:...`，但 `get_model_config` 返回的 `api_key` 为空，说明解密失败，应检查密钥管理配置；
- 不建议直接手工编辑加密后的密钥值，推荐用程序接口更新。

### 7.4 文本生成结果异常

- 不同后端返回结构差异较大，`generate_text` 已做基础兼容，但非典型返回结构会被整体转为 JSON 文本返回；
- 若后端返回错误（如鉴权失败、模型不存在），`generate_text` 会在 `error` 字段中写入原始错误信息，可结合日志排查。

---

> 本文档严格基于当前 `src/model_manager.py` 源码和对应设计文档，仅描述真实存在的函数、参数和配置字段，不包含任何未实现的“模型调度中心”“多租户管理”等扩展能力。如需在本模块之上构建更复杂的模型管理服务（如 Web 控制台、多项目隔离），请在业务层自行封装。 

### 2. vLLM 模型

```python
vllm_config = {
    'name': 'local-llama',
    'type': 'vllm',
    'url': 'http://localhost:8000',   # vLLM服务地址
    'api_key': '',                    # 可选
    'timeout': 300
}
```

**注意事项:**
- URL会自动追加 `/generate` 路径
- API密钥可选，取决于vLLM服务配置
- 建议设置较短的超时时间

### 3. SGlang 模型

```python
sglang_config = {
    'name': 'sglang-model',
    'type': 'sglang',
    'url': 'http://localhost:30000',  # SGlang服务地址
    'api_key': '',                    # 可选
    'timeout': 300
}
```

**注意事项:**
- URL会自动追加 `/generate` 路径
- 使用SGlang特定的请求格式
- 支持采样参数配置

### 4. Ollama 模型

```python
ollama_config = {
    'name': 'ollama-llama3',
    'type': 'ollama',
    'url': 'http://localhost:11434',  # Ollama服务地址
    'model_name': 'llama3:8b',        # 可选，指定Ollama模型
    'timeout': 300
}
```

**注意事项:**
- URL会自动追加 `/api/generate` 路径
- 不需要API密钥
- 模型名称用于指定具体的Ollama模型

## 错误处理

### 1. 常见错误类型

| 错误类型 | 原因 | 解决方案 |
|---------|------|---------|
| `网络请求失败: Connection refused` | 模型服务未启动 | 检查模型服务状态 |
| `HTTP 401: Unauthorized` | API密钥错误 | 检查并更新API密钥 |
| `HTTP 404: Not Found` | URL路径错误 | 检查API地址配置 |
| `HTTP 429: Too Many Requests` | 请求频率过高 | 增加请求间隔或检查配额 |
| `网络请求失败: Timeout` | 响应超时 | 增加timeout设置或检查网络 |

### 2. 调试技巧

```python
# 启用详细日志
import logging
logging.getLogger('model_manager').setLevel(logging.DEBUG)

# 查看详细错误信息
result = model_manager.test_model('problem-model')
if not result['success']:
    print(f"错误详情: {result['error_msg']}")
    print(f"响应时间: {result['response_time']}ms")
```

## 性能优化

### 1. 连接测试优化

```python
# 设置合理的超时时间
short_timeout_config = {
    'name': 'fast-model',
    'type': 'vllm',
    'url': 'http://localhost:8000',
    'timeout': 10  # 快速测试，10秒超时
}

# 批量测试时使用线程池（功能规划中）
# 当前版本为串行测试，未来版本将支持并行测试
```

### 2. 配置缓存

```python
# 获取配置时会自动缓存
config = model_manager.get_model_config('model-name')  # 第一次读取配置文件
config = model_manager.get_model_config('model-name')  # 使用内存缓存
```

## 安全最佳实践

### 1. API密钥管理

- 所有API密钥自动加密存储
- 配置文件中不会显示明文密钥
- 支持密钥轮换和更新

```python
# 查看配置时API密钥会被隐藏
all_models = model_manager.get_all_models()
print(all_models['openai-gpt4']['api_key'])  # 输出: ***encrypted***
```

### 2. 网络安全

- 支持HTTPS连接
- 自定义请求头配置
- 超时保护机制

## 集成示例

### 1. 与蒸馏生成模块集成

```python
# 在蒸馏生成模块中使用
from src.model_manager import model_manager

def get_available_models_for_distill():
    """获取可用于蒸馏的模型列表"""
    active_models = model_manager.get_active_models()
    return [model['name'] for model in active_models]

def validate_model_before_distill(model_name):
    """蒸馏前验证模型可用性"""
    result = model_manager.test_model(model_name)
    if not result['success']:
        raise Exception(f"模型不可用: {result['error_msg']}")
    return True
```

### 2. 与UI界面集成

```python
# 在UI模块中使用
import gradio as gr
from src.model_manager import model_manager

def refresh_model_list():
    """刷新模型列表供UI使用"""
    models = model_manager.get_all_models()
    model_choices = []
    for name, config in models.items():
        status_icon = "✓" if config['status'] == 'online' else "✗"
        model_choices.append(f"{status_icon} {name} ({config['type']})")
    return model_choices

def test_model_connection(model_name):
    """UI中的模型测试功能"""
    result = model_manager.test_model(model_name)
    if result['success']:
        return f"✓ 连接成功，响应时间: {result['response_time']}ms"
    else:
        return f"✗ 连接失败: {result['error_msg']}"
```

## 扩展开发

### 1. 新增模型类型

要支持新的模型类型，需要：

1. 在 `ModelType` 枚举中添加新类型
2. 在 `supported_types` 配置中添加
3. 实现对应的 `_test_xxx_connection` 方法
4. 更新配置验证逻辑

```python
# 示例：添加新的模型类型
class ModelType(Enum):
    # ... 现有类型
    CUSTOM = "custom"

def _test_custom_connection(self, url: str, api_key: str, timeout: int) -> Dict[str, Any]:
    """测试自定义模型连接"""
    # 实现自定义模型的连接测试逻辑
    pass
```

### 2. 自定义连接测试

```python
# 继承ModelManager类实现自定义功能
class CustomModelManager(ModelManager):
    def __init__(self):
        super().__init__()
        self.custom_test_prompts = {
            'chinese': '你好，请介绍一下自己',
            'english': 'Hello, please introduce yourself',
            'code': 'def hello(): return "world"'
        }
    
    def test_model_with_custom_prompt(self, model_name: str, prompt_type: str = 'chinese'):
        """使用自定义提示词测试模型"""
        original_prompt = self.test_prompt
        self.test_prompt = self.custom_test_prompts.get(prompt_type, original_prompt)
        
        result = self.test_model(model_name)
        
        # 恢复原始提示词
        self.test_prompt = original_prompt
        return result
```

## 日志和监控

### 1. 日志配置

```python
# 模型管理器会自动记录详细日志
# 日志文件位置: ./data/logs/{date}/model_manager.log

# 日志级别说明:
# INFO: 正常操作（添加、删除模型）
# WARNING: 连接测试失败
# ERROR: 配置错误、系统异常
# DEBUG: 详细调试信息
```

### 2. 监控指标

```python
# 获取关键监控指标
stats = model_manager.get_model_statistics()

# 可监控的指标:
# - 模型总数和在线数量
# - 各类型模型分布
# - 平均响应时间
# - 错误率统计
```

## 故障排除

### 1. 模型连接失败

**问题**: 模型测试总是失败
**排查步骤**:
1. 检查模型服务是否正常运行
2. 验证URL地址和端口
3. 确认API密钥正确性
4. 检查网络连接
5. 查看详细错误日志

### 2. 配置丢失

**问题**: 模型配置意外丢失
**解决方案**:
1. 检查 `config.yaml` 文件权限
2. 查看配置管理器日志
3. 从备份恢复配置

### 3. 性能问题

**问题**: 模型测试响应慢
**优化方案**:
1. 调整timeout设置
2. 检查网络延迟
3. 优化模型服务配置
4. 使用本地模型减少网络开销

## 版本历史

- **v1.0** (当前版本)
  - 支持vLLM、OpenAI、SGlang、Ollama四种模型类型
  - 实现完整的模型管理功能
  - 支持API密钥加密存储
  - 提供命令行工具
  - 集成连接测试和状态监控

## 技术支持

如果在使用过程中遇到问题：

1. 查看详细日志文件
2. 使用命令行工具进行调试
3. 检查模型服务状态
4. 验证网络连接性
5. 参考本文档的故障排除章节

---

*本文档随软件版本持续更新，请关注最新版本*
