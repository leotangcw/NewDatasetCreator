# 核心功能_字段提取模块配置和调用指南

> **版本**: v2.0  
> **模块**: `src/field_extractor.py`（字段提取核心模块）  
> **最后更新**: 2025-11-14  
> **对应设计文档**: `DesignFiles/核心功能_字段提取模块设计文档.md`

## 目录

1. [模块概述](#1-模块概述)
2. [环境与依赖](#2-环境与依赖)
3. [核心数据结构](#3-核心数据结构)
4. [Python 调用方式](#4-python-调用方式)
5. [命令行用法](#5-命令行用法)
6. [输出文件与目录结构](#6-输出文件与目录结构)
7. [常见问题与排查](#7-常见问题与排查)

---

## 1. 模块概述

`src/field_extractor.py` 是数据处理流水线中的“字段识别与选择性提取”模块，主要负责：

- 对 JSON/JSONL/CSV/Excel 等格式的数据文件进行字段探测；
- 返回字段名、类型和样本信息，供后续交互界面或配置使用；
- 在给定字段列表和过滤条件的情况下，对原始文件进行分片读取、条件过滤和字段重命名，并输出新的文件；
- 记录提取过程的元数据，以便追踪和排查。

模块依赖基础支撑层（配置、日志、状态管理等），具体依赖关系可参考设计文档，本指南不再重复架构细节，只关注调用方式和参数配置。

---

## 2. 环境与依赖

### 2.1 安装依赖

在项目根目录安装统一依赖：

```bash
pip install -r requirements.txt
```

字段提取模块依赖 `pandas`、`jsonlines`、`openpyxl` 等库，均已在 `requirements.txt` 中声明。

### 2.2 配置与目录结构

模块通过 `ConfigManager` 读取全局配置（如数据根目录、日志目录、默认编码等），典型目录结构如下（仅列与本模块相关部分）：

```text
data/
  raw/          # 原始数据
  processed/    # 各阶段处理结果
  temp/         # 临时文件
  logs/         # 日志
```

字段提取的输出目录一般在 `processed` 下按任务或模块划分，具体规则以设计文档和源码实现为准。

---

## 3. 核心数据结构

### 字段信息结构（FieldInfo）

```python
class FieldInfo(TypedDict):
  name: str                    # 字段名称
  type: str                    # 字段类型（string/number/boolean/...）
  sample_values: List[Any]     # 若干非空示例值
  null_ratio: float            # 空值比例（0~1）
```

### 过滤条件结构（FilterCondition）

```python
class FilterCondition(TypedDict):
  field: str                   # 目标字段名
  op: str                      # 运算符字符串，具体支持集合以源码为准
  value: Union[str, int, float, None]  # 比较值（部分操作符可能忽略）
```

### 任务参数结构（TaskParams）

```python
class TaskParams(TypedDict, total=False):
  # 基础参数
  task_id: str                 # 任务唯一标识
  source_path: str             # 源文件路径

  # 字段配置
  selected_fields: List[str]            # 选中字段列表
  field_rename: Dict[str, str]         # 字段重命名映射

  # 过滤配置
  filter_conditions: List[FilterCondition]  # 过滤条件列表
  filter_logic: str                        # 逻辑关系："and" / "or"

  # 输出配置
  output_dir: str              # 输出目录
  target_format: str           # 目标格式（如 jsonl/csv 等）
  encoding: str                # 输出编码

  # 处理参数
  chunk_size: int              # 分片大小
  resume: bool                 # 是否允许断点续传
```

> 以上类型定义均来源于当前源码，如有变动以 `src/field_extractor.py` 中的实际定义为准。

---

## 4. Python 调用方式

### 4.1 初始化与字段识别

```python
from src.field_extractor import FieldExtractor

extractor = FieldExtractor()
ok = extractor.init_extractor()  # 初始化配置和环境
if not ok:
  raise RuntimeError("字段提取器初始化失败")

fields = extractor.get_fields("./data/raw/dataset.jsonl")
for f in fields:
  print(f["name"], f["type"], f["null_ratio"], f["sample_values"])
```

`get_fields` 会根据文件扩展名和内容自动判断格式，返回字段信息列表。支持的具体格式类型和探测逻辑以源码为准。

### 4.2 字段提取（核心流程）

```python
from src.field_extractor import FieldExtractor, TaskParams

extractor = FieldExtractor()
extractor.init_extractor()

params: TaskParams = {
  "task_id": "extract_20251114_001",
  "source_path": "./data/raw/train.jsonl",
  "selected_fields": ["instruction", "output", "score"],
  "output_dir": "./data/processed",
  "target_format": "jsonl",
  "encoding": "utf-8",
  "chunk_size": 1000,
  "resume": True,
}

output_path = extractor.extract_fields(params)
print("输出文件:", output_path)
```

### 4.3 含字段重命名的提取

```python
params: TaskParams = {
  "task_id": "extract_rename_001",
  "source_path": "./data/raw/dataset.csv",
  "selected_fields": ["question", "answer", "rating"],
  "field_rename": {
    "question": "instruction",
    "answer": "output",
    "rating": "score",
  },
  "output_dir": "./data/processed",
  "target_format": "jsonl",
  "encoding": "utf-8",
}

output_path = extractor.extract_fields(params)
```

### 4.4 含过滤条件的提取

#### 数值范围过滤

```python
from src.field_extractor import FilterCondition

filter_conditions: list[FilterCondition] = [
  {"field": "score", "op": ">=", "value": 0.8},
]

params: TaskParams = {
  "task_id": "extract_filter_score",
  "source_path": "./data/raw/dataset.jsonl",
  "selected_fields": ["instruction", "output", "score"],
  "filter_conditions": filter_conditions,
  "filter_logic": "and",
  "output_dir": "./data/processed",
  "target_format": "jsonl",
}

output_path = extractor.extract_fields(params)
```

#### 字符串长度过滤

```python
filter_conditions = [
  {"field": "instruction", "op": "len_gt", "value": 10},
]

params: TaskParams = {
  "task_id": "extract_filter_length",
  "source_path": "./data/raw/dataset.jsonl",
  "selected_fields": ["instruction", "output"],
  "filter_conditions": filter_conditions,
  "filter_logic": "and",
  "output_dir": "./data/processed",
  "target_format": "jsonl",
}
```

#### 字符串内容过滤

```python
filter_conditions = [
  {"field": "instruction", "op": "contains", "value": "机器学习"},
]
```

#### 空值过滤

```python
filter_conditions = [
  {"field": "instruction", "op": "not_null", "value": None},
]
```

#### 多条件组合过滤

```python
filter_conditions = [
    {"field": "score", "op": ">=", "value": 0.8},
    {"field": "instruction", "op": "len_gt", "value": 10},
]

params_and: TaskParams = {
    "task_id": "extract_multi_and",
    "source_path": "./data/raw/dataset.jsonl",
    "selected_fields": ["instruction", "output", "score"],
    "filter_conditions": filter_conditions,
    "filter_logic": "and",
    "output_dir": "./data/processed",
    "target_format": "jsonl",
}

params_or: TaskParams = {
    "task_id": "extract_multi_or",
    "source_path": "./data/raw/dataset.jsonl",
    "selected_fields": ["instruction", "output", "score"],
    "filter_conditions": filter_conditions,
    "filter_logic": "or",
    "output_dir": "./data/processed",
    "target_format": "jsonl",
}
```
---

## 5. 命令行用法

字段提取模块提供命令行入口，主要通过 `--action` 参数区分“字段识别”和“字段提取”两类操作。具体参数列表以源码中的 `argparse` 定义为准，这里给出典型调用方式：

### 5.1 字段识别

```bash
python -m src.field_extractor \
  --action get_fields \
  --source_path ./data/raw/dataset.jsonl
```

常见参数：

- `--action`：`get_fields`；
- `--source_path`：源文件路径；
- 部分实现可能提供额外选项控制输出方式（如是否打印详细字段信息），以实际源码为准。

### 5.2 字段提取

```bash
python -m src.field_extractor \
  --action extract \
  --task_id extract_001 \
  --source_path ./data/raw/train.jsonl \
  --selected_fields instruction,output,score \
  --target_format jsonl \
  --output_dir ./data/processed
```

命令行参数通常包括：

- `--task_id`：任务 ID；
- `--source_path`：源文件路径；
- `--selected_fields`：逗号分隔的字段名列表；
- `--field_rename`：可选，JSON 字符串形式的重命名映射；
- `--filter_conditions` / `--filter_logic`：可选，JSON 字符串形式的过滤条件及逻辑；
- `--target_format`：目标格式；
- `--output_dir`：输出目录等。

具体的参数名和支持情况请以当前版本的 `main()` 中解析逻辑为准。

---

## 6. 输出文件与目录结构

字段提取成功后，模块会在指定输出目录下生成：

- 提取后的数据文件（格式由 `target_format` 决定，如 `.jsonl`/`.csv` 等）；
- 一个描述任务配置和结果的元数据文件（名称和字段结构以 `meta` 相关实现为准）；
- 可能还会生成字段信息、过滤规则等辅助文件（如当前实现包含）。

目录层级通常包含 `task_id` 维度，便于按任务归档。具体文件名与结构请参考设计文档以及 `extract_fields` 中的实际实现。

---

## 7. 常见问题与排查

本节仅基于当前模块真实行为给出排查建议，不涉及源码中不存在的接口或错误码体系。

### 7.1 常见问题

- **文件格式不支持或解析失败**：
  - 检查源文件扩展名是否在当前实现支持的列表中（如 csv/json/jsonl/excel 等）；
  - 对于结构异常的 JSON/JSONL，请先手工抽样检查是否存在语法错误或混合格式。
- **字段不存在或拼写错误**：
  - 在配置 `selected_fields` 或 `filter_conditions` 之前，先通过 `get_fields` 获取字段列表并核对名称；
  - 确保重命名映射中的键都是源数据中存在的字段。
- **过滤条件无效或导致结果为空**：
  - 检查 `op` 的取值是否在当前实现支持集合中（可参考源码中条件评估函数）；
  - 先在小样本上测试过滤逻辑，确认条件表达式正确。

### 7.2 性能与稳定性

- 对于大文件，建议合理设置 `chunk_size`，避免一次性加载过多行；
- 使用 `resume` 时，确保 `task_id` 在重试前后一致，以便状态管理逻辑正确复用；
- 如遇到内存或性能瓶颈，可先通过格式转换模块将数据预处理为更适合流式读取的格式（例如 JSONL）。

---

> 本文档严格基于当前 `src/field_extractor.py` 源码和 `DesignFiles/核心功能_字段提取模块设计文档.md`，仅描述实际存在的类型、参数和调用方式，不包含未来扩展或示例前端/API 封装。开发者可在此模块之上自由设计 Web API、前端页面和调度系统。 
