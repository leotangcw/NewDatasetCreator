# 核心功能_数据清洗模块配置和调用指南 (v2)

本指南说明新版数据清洗(data_cleaner)模块的参数、操作语义与 CLI 使用示例。

## 支持的清洗操作
| 操作 | 说明 | 关键参数 |
|------|------|----------|
| remove_empty | 按字段空值过滤 | remove_empty_fields, empty_mode(any/all) |
| deduplicate | 模糊去重(占位, 后续优化) | dedup_field, dedup_threshold |
| filter_sensitive | 敏感词处理(三种动作) | sensitive_words, sensitive_action, sensitive_replacement |
| pii_desensitize | 个人信息正则脱敏 | pii_enable, pii_replacements / default |
| normalize_text | 文本标准化 | normalize_modes |
| desensitize | 旧版字段脱敏(兼容) | desensitize_fields |

## 参数详解
- remove_empty_fields: 指定需检查的字段。缺省=全部字段。
- empty_mode: any(任意字段为空即丢弃)/all(全部为空才丢弃)。
- dedup_field: 参与模糊去重的字段；缺失将跳过去重。
- dedup_threshold: 相似度阈值(0-1)，默认配置文件值。
- sensitive_words: 敏感词列表。
- sensitive_action: drop_record | remove_word | replace_word。
- sensitive_replacement: 当 sensitive_action=replace_word 时的替换文本(默认 *** )。
- pii_enable: 启用的 PII 分类集合，如 id_card phone email bank_card ip passport。
- pii_replacements: dict，每个分类映射替换文本；支持 default 键。
- normalize_modes: 可选组合 unicode_nfc fullwidth lowercase collapse_newlines。
- desensitize_fields: 旧字段脱敏映射，如 {"user":"mask","email":"email"}。

## PII 分类说明
| 分类 | 正则意图 |
|------|----------|
| id_card | 中国身份证 18 位(含校验 X) |
| phone | 1 开头 11 位手机号 |
| email | 邮箱地址 |
| bank_card | 13-19 位数字 (未做 Luhn 校验) |
| ip | IPv4 地址 |
| passport | 简单匹配护照/通行证号样式 |

替换策略: 优先使用指定分类替换值 -> default -> <分类名>。

## 文本标准化基础处理
无论选择哪些模式，都会执行: 去首尾空白 + 多空白折叠为单空格。额外模式：
- unicode_nfc: Unicode 规范化 NFC。
- fullwidth: 全角转半角。
- lowercase: 转小写。
- collapse_newlines: 多个连续空行折叠为单个空行。

## CLI 使用示例
1. 去除空值 (任一字段为空) + 标准化
```
python -m src.data_cleaner clean --source data.jsonl --operations remove_empty normalize_text \
  --remove-empty-fields instruction output --empty-mode any --normalize-modes unicode_nfc fullwidth
```
2. 敏感词替换 + PII 脱敏
```
python -m src.data_cleaner clean --source data.jsonl --operations filter_sensitive pii_desensitize \
  --sensitive-words 密码 身份证 --sensitive-action replace_word --sensitive-replacement *** \
  --pii-enable id_card phone email --pii-replacement-default <PII>
```
3. 仅丢弃含敏感词记录
```
python -m src.data_cleaner clean --source data.jsonl --operations filter_sensitive \
  --sensitive-words 密码 身份证 --sensitive-action drop_record
```
4. PII 分类分别替换
```
python -m src.data_cleaner clean --source data.jsonl --operations pii_desensitize \
  --pii-enable id_card phone email bank_card \
  --pii-replacement-default <PII> --pii-replacement id_card:<ID> --pii-replacement phone:<TEL>
```
5. 模糊去重占位 (后续算法升级)
```
python -m src.data_cleaner clean --source data.jsonl --operations deduplicate \
  --dedup-field instruction --dedup-threshold 0.95
```
6. 旧版字段脱敏兼容
```
python -m src.data_cleaner clean --source data.jsonl --operations desensitize \
  --desensitize-fields user:mask email:email
```

## 输出文件
- cleaned.<ext>: 清洗后文件
- clean_report.json: 含 statistics、summary、参数
- meta.json: 元数据 (含 operations_summary)

## 升级注意
- remove_duplicates 已废弃；如需要精确重复删除，请等待新版 deduplicate 合并实现。
- 建议逐步迁移旧 desensitize 到 pii_desensitize（适用于任意字段内的匹配）。

## 后续路线
- deduplicate 算法：计划引入分段哈希 / SimHash / MinHash 提高效率。
- PII 校验强化：身份证校验码、银行卡 Luhn 校验、邮箱域白名单等。
- 性能优化：流式正则替换 + 并发处理（需要线程安全评估）。

如有新增需求请在需求文档补充或提交 issue。
