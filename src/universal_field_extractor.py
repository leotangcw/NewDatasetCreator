#!/usr/bin/env python3
"""
é€šç”¨å­—æ®µæå–å™¨ - æ”¯æŒåµŒå¥—JSONå­—æ®µæå–

è¿™ä¸ªæ¨¡å—æä¾›äº†å¯¹å¤æ‚åµŒå¥—JSONç»“æ„çš„å­—æ®µæå–åŠŸèƒ½ï¼Œ
æ”¯æŒä»å¤§æ–‡ä»¶ä¸­é€’å½’æå–æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬æ·±å±‚åµŒå¥—çš„å­—æ®µã€‚
"""

import json
from .dependencies import pd, ijson, HAS_IJSON
from typing import List, Dict, Any, Set, Union, Optional
import os
from collections import defaultdict


class UniversalFieldExtractor:
    """é€šç”¨å­—æ®µæå–å™¨ï¼Œæ”¯æŒåµŒå¥—JSONç»“æ„"""
    
    def __init__(self):
        self.extracted_fields = set()
        self.field_examples = defaultdict(list)
    
    def _extract_nested_fields(self, data: Any, prefix: str = "") -> Set[str]:
        """é€’å½’æå–åµŒå¥—å­—æ®µ
        
        Args:
            data: è¦åˆ†æçš„æ•°æ®
            prefix: å­—æ®µå‰ç¼€
            
        Returns:
            Set[str]: æ‰€æœ‰å­—æ®µåç§°çš„é›†åˆ
        """
        fields = set()
        
        if isinstance(data, dict):
            for key, value in data.items():
                current_field = f"{prefix}.{key}" if prefix else key
                fields.add(current_field)
                
                # ä¿å­˜å­—æ®µç¤ºä¾‹å€¼
                if len(self.field_examples[current_field]) < 3:
                    self.field_examples[current_field].append(value)
                
                # é€’å½’å¤„ç†åµŒå¥—å¯¹è±¡
                if isinstance(value, (dict, list)):
                    nested_fields = self._extract_nested_fields(value, current_field)
                    fields.update(nested_fields)
                    
        elif isinstance(data, list) and data:
            # å¤„ç†åˆ—è¡¨ï¼šä¸ºç¬¬ä¸€ä¸ªå…ƒç´ ç”Ÿæˆå¸¦ç´¢å¼•çš„å­—æ®µè·¯å¾„
            if isinstance(data[0], dict):
                # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œåˆ†æç¬¬ä¸€ä¸ªå­—å…¸ï¼Œå¹¶ç”Ÿæˆå¸¦[0]ç´¢å¼•çš„è·¯å¾„
                array_prefix = f"{prefix}[0]" if prefix else "[0]"
                nested_fields = self._extract_nested_fields(data[0], array_prefix)
                fields.update(nested_fields)
            elif isinstance(data[0], list):
                # å¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼Œç»§ç»­é€’å½’
                array_prefix = f"{prefix}[0]" if prefix else "[0]"
                nested_fields = self._extract_nested_fields(data[0], array_prefix)
                fields.update(nested_fields)
        
        return fields
    
    def _get_nested_value(self, data: Dict, field_path: str) -> Any:
        """æ ¹æ®å­—æ®µè·¯å¾„è·å–åµŒå¥—å€¼ï¼Œæ”¯æŒæ•°ç»„ç´¢å¼•
        
        Args:
            data: æºæ•°æ®å­—å…¸
            field_path: å­—æ®µè·¯å¾„ï¼Œå¦‚ "reasoning.teacher" æˆ– "reasoning[0].full_response"
            
        Returns:
            Any: å­—æ®µå€¼ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        import re
        
        try:
            current = data
            
            # åˆ†å‰²è·¯å¾„ï¼Œå¤„ç†æ•°ç»„ç´¢å¼•
            path_parts = []
            remaining_path = field_path
            
            while remaining_path:
                # åŒ¹é…å­—æ®µåå’Œå¯é€‰çš„æ•°ç»„ç´¢å¼•: key[index] æˆ– key
                match = re.match(r'^([^.\[]+)(\[(\d+)\])?(\.(.*))?$', remaining_path)
                if match:
                    key = match.group(1)  # å­—æ®µå
                    index = match.group(3)  # æ•°ç»„ç´¢å¼•ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    rest = match.group(5)  # å‰©ä½™è·¯å¾„
                    
                    path_parts.append((key, int(index) if index is not None else None))
                    remaining_path = rest if rest else ''
                else:
                    # å¤„ç†ç®€å•æƒ…å†µï¼šæ²¡æœ‰æ•°ç»„ç´¢å¼•
                    if '.' in remaining_path:
                        key, remaining_path = remaining_path.split('.', 1)
                    else:
                        key = remaining_path
                        remaining_path = ''
                    path_parts.append((key, None))
            
            # éå†è·¯å¾„è·å–å€¼
            for key, index in path_parts:
                if current is None:
                    return None
                
                # è·å–å­—æ®µå€¼
                if isinstance(current, dict) and key in current:
                    current = current[key]
                else:
                    return None
                
                # å¦‚æœæœ‰æ•°ç»„ç´¢å¼•ï¼Œè®¿é—®æ•°ç»„å…ƒç´ 
                if index is not None:
                    if isinstance(current, list) and 0 <= index < len(current):
                        current = current[index]
                    else:
                        return None
            
            return current
        except (KeyError, TypeError, AttributeError, IndexError, ValueError):
            return None
    
    def extract_fields_from_file(self, file_path: str, sample_size: int = 100) -> List[Dict[str, Any]]:
        """ä»æ–‡ä»¶ä¸­æå–å­—æ®µä¿¡æ¯
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            sample_size: é‡‡æ ·å¤§å°
            
        Returns:
            List[Dict]: å­—æ®µä¿¡æ¯åˆ—è¡¨
        """
        self.extracted_fields.clear()
        self.field_examples.clear()
        
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯HuggingFaceæ•°æ®é›†ç›®å½•
            if os.path.isdir(file_path):
                hf_result = self._extract_from_huggingface_dataset(file_path, sample_size)
                if hf_result:
                    return hf_result
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ ¼å¼
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext == '.jsonl':
                return self._extract_from_jsonl(file_path, sample_size)
            elif file_ext == '.json':
                return self._extract_from_json(file_path, sample_size)
            elif file_ext == '.csv':
                return self._extract_from_csv(file_path, sample_size)
            elif file_ext in ['.xlsx', '.xls']:
                return self._extract_from_excel(file_path, sample_size)
            elif file_ext == '.arrow':
                return self._extract_from_arrow(file_path, sample_size)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                
        except Exception as e:
            print(f"å­—æ®µæå–é”™è¯¯: {str(e)}")
            return []
    
    def _extract_from_jsonl(self, file_path: str, sample_size: int) -> List[Dict[str, Any]]:
        """ä»JSONLæ–‡ä»¶æå–å­—æ®µ"""
        all_fields = set()
        sample_count = 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if sample_count >= sample_size:
                    break
                    
                line = line.strip()
                if line:
                    try:
                        data = json.loads(line)
                        fields = self._extract_nested_fields(data)
                        all_fields.update(fields)
                        sample_count += 1
                    except json.JSONDecodeError:
                        continue
        
        return self._format_field_info(all_fields)
    
    def _extract_from_json(self, file_path: str, sample_size: int) -> List[Dict[str, Any]]:
        """ä»JSONæ–‡ä»¶æå–å­—æ®µ"""
        all_fields = set()
        
        if HAS_IJSON:
            try:
                with open(file_path, 'rb') as f:
                    # å°è¯•æµå¼è§£ææ•°ç»„
                    objects = ijson.items(f, 'item')
                    count = 0
                    for item in objects:
                        if count >= sample_size:
                            break
                        if isinstance(item, dict):
                            fields = self._extract_nested_fields(item)
                            all_fields.update(fields)
                        count += 1
                    
                    if count > 0:
                        return self._format_field_info(all_fields)
            except Exception:
                # è§£æå¤±è´¥å›é€€
                pass

        # å›é€€åˆ°æ™®é€šåŠ è½½
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            # å¦‚æœæ˜¯æ•°ç»„ï¼Œåˆ†æå‰Nä¸ªå…ƒç´ 
            for i, item in enumerate(data[:sample_size]):
                if isinstance(item, dict):
                    fields = self._extract_nested_fields(item)
                    all_fields.update(fields)
        elif isinstance(data, dict):
            # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡
            fields = self._extract_nested_fields(data)
            all_fields.update(fields)
        
        return self._format_field_info(all_fields)
    
    def _extract_from_csv(self, file_path: str, sample_size: int) -> List[Dict[str, Any]]:
        """ä»CSVæ–‡ä»¶æå–å­—æ®µ"""
        df = pd.read_csv(file_path, nrows=sample_size)
        fields = list(df.columns)
        
        field_info = []
        for field in fields:
            field_info.append({
                'name': field,
                'type': str(df[field].dtype),
                'examples': df[field].dropna().head(3).tolist(),
                'nested': False
            })
        
        return field_info
    
    def _extract_from_huggingface_dataset(self, dataset_path: str, sample_size: int) -> Optional[List[Dict[str, Any]]]:
        """ä»HuggingFaceæ•°æ®é›†ç›®å½•æå–å­—æ®µ
        
        Args:
            dataset_path: æ•°æ®é›†ç›®å½•è·¯å¾„
            sample_size: é‡‡æ ·å¤§å°
            
        Returns:
            Optional[List[Dict]]: å­—æ®µä¿¡æ¯åˆ—è¡¨ï¼Œå¦‚æœä¸æ˜¯HFæ•°æ®é›†è¿”å›None
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯HuggingFaceæ•°æ®é›†ç›®å½•ç»“æ„
            dataset_dir = os.path.join(dataset_path, 'dataset')
            if not os.path.exists(dataset_dir):
                return None
            
            # æŸ¥æ‰¾trainç›®å½•ä¸‹çš„dataset_info.json
            train_dir = os.path.join(dataset_dir, 'train')
            if not os.path.exists(train_dir):
                return None
                
            dataset_info_path = os.path.join(train_dir, 'dataset_info.json')
            if not os.path.exists(dataset_info_path):
                return None
            
            # è¯»å–dataset_info.jsonè·å–å­—æ®µä¿¡æ¯
            with open(dataset_info_path, 'r', encoding='utf-8') as f:
                dataset_info = json.load(f)
            
            features = dataset_info.get('features', {})
            if not features:
                return None
            
            # ä»featuresæå–å­—æ®µä¿¡æ¯
            all_fields = set()
            self._extract_features_fields(features, "", all_fields)
            
            # å°è¯•ä»å®é™…çš„Arrowæ–‡ä»¶ä¸­è·å–ç¤ºä¾‹æ•°æ®
            arrow_files = [f for f in os.listdir(train_dir) if f.endswith('.arrow')]
            if arrow_files:
                try:
                    from .dependencies import pq, pa
                    
                    # è¯»å–ç¬¬ä¸€ä¸ªArrowæ–‡ä»¶çš„å°‘é‡æ•°æ®ä½œä¸ºç¤ºä¾‹
                    arrow_path = os.path.join(train_dir, arrow_files[0])
                    table = pa.ipc.open_file(arrow_path).read_all()
                    
                    # è½¬æ¢ä¸ºpandas DataFrameå¹¶è·å–å‰å‡ è¡Œä½œä¸ºç¤ºä¾‹
                    df = table.to_pandas()
                    if not df.empty:
                        sample_data = df.head(min(sample_size, len(df)))
                        for field in all_fields:
                            try:
                                value = self._get_nested_value(sample_data.iloc[0].to_dict(), field)
                                if value is not None and len(self.field_examples[field]) < 3:
                                    self.field_examples[field].append(value)
                            except:
                                pass
                                
                except ImportError:
                    print("PyArrowæœªå®‰è£…ï¼Œæ— æ³•è¯»å–Arrowæ–‡ä»¶ç¤ºä¾‹")
                except Exception as e:
                    print(f"è¯»å–Arrowæ–‡ä»¶ç¤ºä¾‹å¤±è´¥: {e}")
            
            return self._format_field_info(all_fields)
            
        except Exception as e:
            print(f"HuggingFaceæ•°æ®é›†å­—æ®µæå–å¤±è´¥: {e}")
            return None
    
    def _extract_features_fields(self, features: Dict[str, Any], prefix: str, all_fields: Set[str]):
        """é€’å½’æå–featuresä¸­çš„å­—æ®µ
        
        Args:
            features: featureså­—å…¸
            prefix: å­—æ®µå‰ç¼€
            all_fields: å­—æ®µé›†åˆ
        """
        for key, value in features.items():
            current_field = f"{prefix}.{key}" if prefix else key
            all_fields.add(current_field)
            
            if isinstance(value, dict):
                if '_type' in value:
                    # è¿™æ˜¯ä¸€ä¸ªç±»å‹å®šä¹‰ï¼Œä¸éœ€è¦è¿›ä¸€æ­¥é€’å½’
                    continue
                else:
                    # é€’å½’å¤„ç†åµŒå¥—å­—æ®µ
                    self._extract_features_fields(value, current_field, all_fields)
            elif isinstance(value, list) and value:
                # å¤„ç†åˆ—è¡¨å­—æ®µï¼Œé€šå¸¸è¡¨ç¤ºæ•°ç»„ç±»å‹
                if isinstance(value[0], dict):
                    array_prefix = f"{current_field}[0]"
                    self._extract_features_fields(value[0], array_prefix, all_fields)
    
    def _extract_from_arrow(self, file_path: str, sample_size: int) -> List[Dict[str, Any]]:
        """ä»Arrowæ–‡ä»¶æå–å­—æ®µ"""
        try:
            from .dependencies import pa
            
            # è¯»å–Arrowæ–‡ä»¶
            table = pa.ipc.open_file(file_path).read_all()
            
            # è·å–å­—æ®µå
            field_names = table.schema.names
            
            # è½¬æ¢ä¸ºpandasè¿›è¡Œç¤ºä¾‹æ•°æ®æå–
            df = table.to_pandas()
            
            field_info = []
            for field in field_names:
                if field in df.columns:
                    examples = df[field].dropna().head(3).tolist()
                    field_info.append({
                        'name': field,
                        'type': str(df[field].dtype),
                        'examples': examples,
                        'nested': False
                    })
            
            return field_info
            
        except ImportError:
            print("PyArrowæœªå®‰è£…ï¼Œæ— æ³•è¯»å–Arrowæ–‡ä»¶")
            return []
        except Exception as e:
            print(f"Arrowæ–‡ä»¶å­—æ®µæå–å¤±è´¥: {e}")
            return []
    
    def _extract_from_excel(self, file_path: str, sample_size: int) -> List[Dict[str, Any]]:
        """ä»Excelæ–‡ä»¶æå–å­—æ®µ"""
        df = pd.read_excel(file_path, nrows=sample_size)
        fields = list(df.columns)
        
        field_info = []
        for field in fields:
            field_info.append({
                'name': field,
                'type': str(df[field].dtype),
                'examples': df[field].dropna().head(3).tolist(),
                'nested': False
            })
        
        return field_info
    
    def _format_field_info(self, fields: Set[str]) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–å­—æ®µä¿¡æ¯"""
        field_info = []
        
        for field in sorted(fields):
            examples = self.field_examples.get(field, [])
            field_info.append({
                'name': field,
                'type': self._infer_type(examples),
                'examples': examples[:3],
                'nested': '.' in field
            })
        
        return field_info
    
    def _infer_type(self, examples: List[Any]) -> str:
        """æ¨æ–­å­—æ®µç±»å‹"""
        if not examples:
            return 'unknown'
        
        first_example = examples[0]
        if isinstance(first_example, str):
            return 'string'
        elif isinstance(first_example, int):
            return 'integer'
        elif isinstance(first_example, float):
            return 'float'
        elif isinstance(first_example, bool):
            return 'boolean'
        elif isinstance(first_example, list):
            return 'array'
        elif isinstance(first_example, dict):
            return 'object'
        else:
            return 'mixed'


# å…¨å±€æå–å™¨å®ä¾‹
_extractor = UniversalFieldExtractor()


def extract_fields_universal(source_path: str, fields: List[str], output_dir: str = None, 
                           field_mapping: Dict[str, str] = None, progress_callback=None) -> str:
    """é€šç”¨å­—æ®µæå–å‡½æ•°ï¼ˆå®Œæ•´ç‰ˆï¼‰
    
    Args:
        source_path: æºæ–‡ä»¶è·¯å¾„
        fields: è¦æå–çš„å­—æ®µåˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        field_mapping: å­—æ®µé‡å‘½åæ˜ å°„
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    import tempfile
    from datetime import datetime
    
    try:
        if progress_callback:
            progress_callback("ğŸ”„ å¼€å§‹å­—æ®µæå–...", 15)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not output_dir:
            # é¿å…ç¡¬ç¼–ç ç»å¯¹è·¯å¾„ï¼Œä¿æŒç›¸å¯¹ root_dir çš„é»˜è®¤ç»“æ„ï¼Œç”±è°ƒç”¨æ–¹ä¼ å…¥æ›´ä½³
            # è¿™é‡Œä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œäº¤ç”±ä¸Šå±‚ä»¥ config ä¸­çš„ root_dir ä¼ å…¥è¦†ç›–
            output_dir = os.path.join('.', 'data', 'processed')
        
        # åˆ›å»ºæå–ç‰¹å®šçš„å­ç›®å½•
        timestamp = int(datetime.now().timestamp())
        # è§„èŒƒåŒ–åˆ†éš”ç¬¦ï¼Œä¿è¯è·¨å¹³å°
        extract_dir = os.path.join(output_dir, f"extract-{timestamp}-{os.urandom(3).hex()}")
        os.makedirs(extract_dir, exist_ok=True)
        
        if progress_callback:
            progress_callback("ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•...", 25)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(source_path))[0]
        output_filename = f"{base_name}_extracted.jsonl"
        output_path = os.path.join(extract_dir, output_filename)
        
        if progress_callback:
            progress_callback("ğŸ“– å¼€å§‹è¯»å–æºæ–‡ä»¶...", 35)
        
        # æ ¹æ®æ–‡ä»¶æ ¼å¼è¿›è¡Œæå–
        file_ext = os.path.splitext(source_path)[1].lower()
        
        if file_ext == '.jsonl':
            success = _extract_jsonl_fields_with_mapping(
                source_path, fields, output_path, field_mapping, progress_callback
            )
        elif file_ext == '.json':
            success = _extract_json_fields_with_mapping(
                source_path, fields, output_path, field_mapping, progress_callback
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        if success:
            # æ¸…ç†æ–‡ä»¶æœ«å°¾çš„å¤šä½™ç©ºè¡Œ
            _clean_extract_file_ending(output_path, file_ext)
            
            if progress_callback:
                progress_callback("âœ… å­—æ®µæå–å®Œæˆï¼", 100)
            return output_path
        else:
            raise Exception("å­—æ®µæå–å¤±è´¥")
            
    except Exception as e:
        if progress_callback:
            progress_callback(f"âŒ æå–å¤±è´¥: {str(e)}", 100)
        raise e


def get_field_names_universal(file_path: str, sample_size: int = 100) -> List[str]:
    """è·å–å­—æ®µåç§°åˆ—è¡¨
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        sample_size: é‡‡æ ·å¤§å°
        
    Returns:
        List[str]: å­—æ®µåç§°åˆ—è¡¨
    """
    field_info = get_fields_universal(file_path, sample_size)
    return [field['name'] for field in field_info]


def get_fields_universal(file_path: str, sample_size: int = 100) -> List[Dict[str, Any]]:
    """è·å–å­—æ®µä¿¡æ¯åˆ—è¡¨ï¼ˆåŸextract_fields_universalçš„åŠŸèƒ½ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        sample_size: é‡‡æ ·å¤§å°
        
    Returns:
        List[Dict]: å­—æ®µä¿¡æ¯åˆ—è¡¨
    """
    return _extractor.extract_fields_from_file(file_path, sample_size)


def _extract_jsonl_fields_with_mapping(source_path: str, fields: List[str], output_path: str, 
                                     field_mapping: Dict[str, str] = None, progress_callback=None) -> bool:
    """ä»JSONLæ–‡ä»¶æå–æŒ‡å®šå­—æ®µï¼ˆå¸¦æ˜ å°„å’Œè¿›åº¦ï¼‰"""
    try:
        total_lines = _count_lines(source_path)
        processed_lines = 0
        
        with open(source_path, 'r', encoding='utf-8') as infile, \
             open(output_path, 'w', encoding='utf-8', newline='\n') as outfile:
            
            for line in infile:
                line = line.strip()
                if line:
                    try:
                        data = json.loads(line)
                        extracted = {}
                        
                        for field in fields:
                            value = _extractor._get_nested_value(data, field)
                            if value is not None:
                                # åº”ç”¨å­—æ®µæ˜ å°„
                                output_field = field_mapping.get(field, field) if field_mapping else field
                                extracted[output_field] = value
                        
                        if extracted:
                            # ä½¿ç”¨åŸç”ŸJSONå†™å…¥ï¼Œç¡®ä¿ç»Ÿä¸€çš„è¡Œç»ˆæ­¢ç¬¦
                            json_line = json.dumps(extracted, ensure_ascii=False)
                            outfile.write(json_line + '\n')
                            
                    except json.JSONDecodeError:
                        continue
                
                processed_lines += 1
                if progress_callback and processed_lines % 1000 == 0:
                    progress = 35 + int((processed_lines / total_lines) * 60)
                    progress_callback(f"ğŸ“ å¤„ç†ä¸­... {processed_lines:,}/{total_lines:,}", progress)
        
        return True
        
    except Exception as e:
        print(f"JSONLå­—æ®µæå–å¤±è´¥: {str(e)}")
        return False


def _extract_json_fields_with_mapping(source_path: str, fields: List[str], output_path: str, 
                                    field_mapping: Dict[str, str] = None, progress_callback=None) -> bool:
    """ä»JSONæ–‡ä»¶æå–æŒ‡å®šå­—æ®µï¼ˆå¸¦æ˜ å°„å’Œè¿›åº¦ï¼‰- ä½¿ç”¨æµå¼å¤„ç†é¿å…OOM"""
    try:
        if progress_callback:
            progress_callback("ğŸ“– å‡†å¤‡è¯»å–JSONæ–‡ä»¶...", 45)
        
        # ä½¿ç”¨ ijson è¿›è¡Œæµå¼è§£æï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½å¤§æ–‡ä»¶
        try:
            import ijson
        except ImportError:
            print("ç¼ºå°‘ ijson åº“ï¼Œå°è¯•ä½¿ç”¨æ™®é€šåŠ è½½æ–¹å¼")
            # å›é€€åˆ°æ™®é€šåŠ è½½ï¼Œä½†ä»éœ€æ³¨æ„å†…å­˜
            return _extract_json_fields_fallback(source_path, fields, output_path, field_mapping, progress_callback)

        file_size = os.path.getsize(source_path)
        processed_count = 0
        
        with open(source_path, 'rb') as infile, \
             open(output_path, 'w', encoding='utf-8', newline='\n') as outfile:
            
            # å°è¯•æ£€æµ‹JSONç»“æ„
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œä½¿ç”¨ items='item'
            # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„å¤„ç†ï¼Œä½†é€šå¸¸æ•°æ®é›†æ˜¯åˆ—è¡¨
            
            # ç®€å•çš„å¯å‘å¼æ£€æŸ¥ï¼šè¯»å–ç¬¬ä¸€ä¸ªéç©ºå­—ç¬¦
            pos = infile.tell()
            first_char = infile.read(1)
            while first_char and first_char.isspace():
                first_char = infile.read(1)
            infile.seek(pos)
            
            is_list = first_char == b'['
            
            if is_list:
                parser = ijson.items(infile, 'item')
            else:
                # å¦‚æœæ˜¯å•ä¸ªå¤§å¯¹è±¡ï¼Œå‡è®¾æˆ‘ä»¬æƒ³æå–é¡¶å±‚å­—æ®µï¼Œæˆ–è€…å®ƒä¸æ˜¯æ ‡å‡†æ•°æ®é›†æ ¼å¼
                # è¿™é‡Œå‡è®¾æ˜¯å•ä¸ªå¯¹è±¡ï¼Œæˆ‘ä»¬åªå¤„ç†ä¸€æ¬¡
                parser = ijson.items(infile, '')
            
            for item in parser:
                if isinstance(item, dict):
                    extracted = {}
                    for field in fields:
                        value = _extractor._get_nested_value(item, field)
                        if value is not None:
                            # åº”ç”¨å­—æ®µæ˜ å°„
                            output_field = field_mapping.get(field, field) if field_mapping else field
                            extracted[output_field] = value
                    
                    if extracted:
                        # ç«‹å³å†™å…¥ï¼Œä¸ç§¯å‹åœ¨å†…å­˜ä¸­
                        json_line = json.dumps(extracted, ensure_ascii=False)
                        outfile.write(json_line + '\n')
                
                processed_count += 1
                if progress_callback and processed_count % 1000 == 0:
                    # ä¼°ç®—è¿›åº¦ï¼ˆåŸºäºæ–‡ä»¶ä½ç½®ï¼‰
                    try:
                        current_pos = infile.tell()
                        progress = 45 + int((current_pos / file_size) * 50)
                        progress_callback(f"ğŸ“ å¤„ç†ä¸­... {processed_count:,} æ¡", progress)
                    except:
                        pass
        
        return True
        
    except Exception as e:
        print(f"JSONå­—æ®µæå–å¤±è´¥: {str(e)}")
        return False

def _extract_json_fields_fallback(source_path: str, fields: List[str], output_path: str, 
                                field_mapping: Dict[str, str] = None, progress_callback=None) -> bool:
    """ä»JSONæ–‡ä»¶æå–æŒ‡å®šå­—æ®µï¼ˆå›é€€æ¨¡å¼ï¼šä¸€æ¬¡æ€§åŠ è½½ï¼‰"""
    try:
        if progress_callback:
            progress_callback("ğŸ“– è¯»å–JSONæ–‡ä»¶(å†…å­˜æ¨¡å¼)...", 45)
        
        with open(source_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ...existing code...
        extracted_data = []
        
        if isinstance(data, list):
            total_items = len(data)
            for i, item in enumerate(data):
                if isinstance(item, dict):
                    extracted = {}
                    for field in fields:
                        value = _extractor._get_nested_value(item, field)
                        if value is not None:
                            # åº”ç”¨å­—æ®µæ˜ å°„
                            output_field = field_mapping.get(field, field) if field_mapping else field
                            extracted[output_field] = value
                    
                    if extracted:
                        extracted_data.append(extracted)
                
                if progress_callback and i % 1000 == 0:
                    progress = 45 + int((i / total_items) * 50)
                    progress_callback(f"ğŸ“ å¤„ç†ä¸­... {i:,}/{total_items:,}", progress)
        
        elif isinstance(data, dict):
            extracted = {}
            for field in fields:
                value = _extractor._get_nested_value(data, field)
                if value is not None:
                    # åº”ç”¨å­—æ®µæ˜ å°„
                    output_field = field_mapping.get(field, field) if field_mapping else field
                    extracted[output_field] = value
            
            if extracted:
                extracted_data.append(extracted)
        
        # ä¿å­˜ä¸ºJSONLæ ¼å¼
        if progress_callback:
            progress_callback("ğŸ’¾ ä¿å­˜æå–ç»“æœ...", 95)
        
        with open(output_path, 'w', encoding='utf-8', newline='\n') as f:
            for item in extracted_data:
                # ä½¿ç”¨åŸç”ŸJSONå†™å…¥ï¼Œç¡®ä¿ç»Ÿä¸€çš„è¡Œç»ˆæ­¢ç¬¦
                json_line = json.dumps(item, ensure_ascii=False)
                f.write(json_line + '\n')
        
        return True
        
    except Exception as e:
        print(f"JSONå­—æ®µæå–(å›é€€æ¨¡å¼)å¤±è´¥: {str(e)}")
        return False


def _count_lines(file_path: str) -> int:
    """å¿«é€Ÿè®¡ç®—æ–‡ä»¶è¡Œæ•°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return sum(1 for _ in f)
    except Exception:
        return 0


def _clean_extract_file_ending(file_path: str, file_format: str, encoding: str = 'utf-8'):
    """æ¸…ç†æå–æ–‡ä»¶æœ«å°¾çš„å¤šä½™ç©ºè¡Œ
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        file_format: æ–‡ä»¶æ ¼å¼
        encoding: æ–‡ä»¶ç¼–ç 
    """
    try:
        if file_format == '.jsonl':
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
            
            # ç§»é™¤æœ«å°¾çš„å¤šä½™æ¢è¡Œç¬¦ï¼Œä½†ä¿ç•™æœ€åä¸€è¡Œçš„æ¢è¡Œç¬¦
            content = content.rstrip('\n') + '\n'
            
            # é‡å†™æ–‡ä»¶ï¼Œç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„è¡Œç»ˆæ­¢ç¬¦
            with open(file_path, 'w', encoding=encoding, newline='\n') as f:
                f.write(content)
                
    except Exception as e:
        print(f"æ¸…ç†æå–æ–‡ä»¶æœ«å°¾å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import tempfile
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = [
        {
            "id": 1,
            "name": "test1",
            "reasoning": {
                "teacher": "AI Assistant",
                "Cognitive_Difficulty": {
                    "level": "medium",
                    "score": 0.6
                }
            }
        },
        {
            "id": 2,
            "name": "test2", 
            "reasoning": {
                "teacher": "Human Expert",
                "Cognitive_Difficulty": {
                    "level": "hard",
                    "score": 0.9
                }
            }
        }
    ]
    
    # åˆ›å»ºä¸´æ—¶JSONLæ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False) as f:
        for item in test_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
        temp_file = f.name
    
    # æµ‹è¯•å­—æ®µæå–
    print("æµ‹è¯•å­—æ®µæå–...")
    fields = get_fields_universal(temp_file)
    print(f"æå–åˆ° {len(fields)} ä¸ªå­—æ®µ:")
    for field in fields:
        print(f"  - {field['name']} ({field['type']}): {field['examples']}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.unlink(temp_file)
    print("æµ‹è¯•å®Œæˆ!")
