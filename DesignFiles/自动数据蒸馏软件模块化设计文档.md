# 自动数据蒸馏软件模块化设计文档（独立模块版）


## 目录

1. [整体架构设计](#1-整体架构设计)
2. [基础支撑模块设计](#2-基础支撑模块设计)
3. [核心功能模块设计](#3-核心功能模块设计)
4. [交互层设计](#4-交互层设计)
5. [数据存储层设计](#5-数据存储层设计)
6. [模块调用关系](#6-模块调用关系)
7. [配置与日志规范](#7-配置与日志规范)
8. [异常处理规范](#8-异常处理规范)
9. [扩展性设计](#9-扩展性设计)
10. [总结](#10-总结)


## 1. 整体架构设计

### 1.1 架构分层与模块划分

采用「**基础支撑层 + 核心功能层 + 交互层 + 数据存储层**」四层架构，所有模块均为独立可执行的Python文件，通过标准化接口交互，实现低耦合、高复用。

| 架构分层       | 包含模块                                  | 核心职责                                                                 | 独立性要求                                   |
|----------------|-------------------------------------------|--------------------------------------------------------------------------|----------------------------------------------|
| 基础支撑层     | 配置管理、日志管理、状态管理、工具函数     | 提供公共能力（配置读写、日志记录、状态持久化、通用工具），支撑所有上层模块 | 不可拆分，所有模块均依赖此层                 |
| 核心功能层     | 数据集下载、格式转换、字段提取、数据合并、模型管理、蒸馏生成、数据管理、数据清洗 | 实现单一业务功能，支持独立调用（命令行/函数接口）                         | 每个模块独立为`.py`文件，仅依赖基础支撑层     |
| 交互层         | 网页UI（Gradio）、命令行入口               | 提供用户交互入口，调用核心功能模块接口，不包含业务逻辑                     | 依赖基础支撑层和核心功能层，无业务逻辑耦合   |
| 数据存储层     | 目录结构规范、文件格式规范                 | 统一数据存储规则，确保数据可追溯、可复用                                 | 所有模块需严格遵循此层规范                   |


### 1.2 架构图

```mermaid
graph TD
    A[交互层] -->|调用函数接口| B[核心功能层]
    B -->|依赖| C[基础支撑层]
    B -->|遵循规范| D[数据存储层]
    C -->|提供能力| A
    C -->|提供能力| B
    
    subgraph 交互层
        A1[网页UI: ui_launcher.py]
        A2[命令行入口: 各模块main函数]
    end
    
    subgraph 核心功能层
        B1[数据集下载: dataset_downloader.py]
        B2[格式转换: format_converter.py]
        B3[字段提取: field_extractor.py]
        B4[数据合并: data_merger.py]
        B5[模型管理: model_manager.py]
        B6[蒸馏生成: distill_generator.py]
        B7[数据管理: data_manager.py]
        B8[数据清洗: data_cleaner.py]  # 新增核心模块
    end
    
    subgraph 基础支撑层
        C1[配置管理: config_manager.py]
        C2[日志管理: log_manager.py]
        C3[状态管理: state_manager.py]
        C4[工具函数: utils.py]
    end
    
    subgraph 数据存储层
        D1[结构化目录]
        D2[文件格式规范]
    end
```


## 2. 基础支撑模块设计

基础支撑模块为公共依赖模块，提供通用能力，所有核心功能模块均通过函数调用使用其能力，**不可独立拆分**，需优先实现。


### 2.1 配置管理模块（`config_manager.py`）

#### 功能定位
统一管理全局配置（如路径、并行数、超时时间），支持配置加载、更新、加密存储（如API密钥），确保所有模块使用一致的配置参数。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `load_config()`         | 从`config.yaml`加载配置到内存             | 无                                | 配置字典（`dict`）      |
| `get_config(key)`       | 获取指定配置项（支持嵌套路径，如`distill.batch_size`） | `key: str`（配置项路径）          | 配置值（任意类型）      |
| `update_config(key, value)` | 更新配置项并写入文件                      | `key: str`，`value: 任意类型`     | `bool`（更新成功与否）  |
| `encrypt_config(key)`   | 加密指定敏感配置（如API密钥）             | `key: str`（敏感配置项路径）      | 加密后的配置字典        |
| `decrypt_config(key)`   | 解密指定敏感配置                          | `key: str`（加密配置项路径）      | 解密后的原始值          |

#### 配置文件格式（`config.yaml`）
```yaml
# 基础配置（所有模块共用）
base:
  root_dir: "./data"                # 主数据目录（默认存储根路径）
  chunk_size: 1000                  # 大文件分片大小（行），所有模块复用
  max_parallel_tasks: 5             # 最大并行任务数（下载/加工/蒸馏共用）
  encoding: "utf-8"                 # 默认文件编码

# 下载模块配置
download:
  timeout: 300                      # 下载超时时间（秒）
  retry_count: 3                    # 下载失败重试次数
  buffer_size: 8192                 # 下载缓冲区大小（字节）
  snapshot_download: False          # 是否启用快照下载（仅Hugging Face）
  encrypt_api_key: True             # 是否加密存储API密钥

# 加工模块配置（格式转换/字段提取/合并/清洗）
process:
  excel_engine: "openpyxl"          # Excel读取引擎
  csv_delimiter: ","                # CSV默认分隔符
  max_preview_rows: 100             # 数据预览默认行数
  dedup_threshold: 0.95             # 数据去重相似度阈值（数据清洗用）

# 模型管理模块配置
model:
  default_timeout: 600              # 模型调用默认超时时间（秒）
  test_prompt: "测试连接"            # 模型连接测试的默认提示词
  supported_types: ["vllm", "openai", "sglang", "ollama"]  # 支持的模型类型

# 蒸馏生成模块配置
distill:
  batch_size: 10                    # 模型批量调用大小
  retry_count: 3                    # 模型调用失败重试次数
  save_interval: 100                # 每处理N条数据保存一次结果（断点续传用）

# 日志模块配置
log:
  level: "INFO"                     # 日志级别（DEBUG/INFO/WARN/ERROR）
  max_file_size: 10485760           # 单个日志文件最大大小（10MB）
  backup_count: 7                   # 日志文件备份数量（保留7天）
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"  # 日志格式
```


### 2.2 日志管理模块（`log_manager.py`）

#### 功能定位
为所有模块提供统一的日志记录能力，支持按模块分类日志、分级输出（DEBUG/INFO/WARN/ERROR）、日志轮转（避免单个文件过大），便于问题定位。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `get_logger(module_name)` | 获取指定模块的日志实例（按模块分日志文件） | `module_name: str`（模块名，如`distill_generator`） | 日志实例（`logging.Logger`） |
| `set_log_level(level)`  | 动态修改全局日志级别                      | `level: str`（DEBUG/INFO/WARN/ERROR） | 无                      |
| `add_log_handler(handler)` | 新增日志处理器（如控制台/文件）          | `handler: logging.Handler`        | 无                      |

#### 日志文件规范
- 存储路径：`{base.root_dir}/logs/[日期]/[模块名].log`（如`./data/logs/20241001/distill_generator.log`）
- 轮转规则：单个文件达`log.max_file_size`时自动分割，保留`log.backup_count`个历史文件
- 日志内容：包含时间、模块名、级别、消息（如`2024-10-01 10:00:00 - distill_generator - INFO - 已处理300行`）


### 2.3 状态管理模块（`state_manager.py`）

#### 功能定位
记录所有任务的状态（运行/暂停/完成/失败）和进度详情，支持状态持久化（写入`state.json`）和实时更新，为断点续传和进度展示提供数据支撑。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `init_state()`          | 初始化状态文件（首次运行时创建`state.json`） | 无                                | 无                      |
| `add_task(task_id, task_type, params)` | 新增任务状态记录                  | `task_id: str`，`task_type: str`（如`download`/`distill`），`params: dict`（任务参数） | 无 |
| `update_state(task_id, key, value)` | 更新任务指定状态字段（如进度）    | `task_id: str`，`key: str`（如`progress`/`status`），`value: 任意类型` | 无 |
| `get_task_state(task_id)` | 获取指定任务的完整状态            | `task_id: str`                    | 任务状态字典（`dict`）  |
| `list_tasks(status=None)` | 列出符合状态的所有任务（如运行中） | `status: str`（可选，如`running`） | 任务列表（`list[dict]`） |
| `delete_task(task_id)`  | 删除已完成/失败的任务状态记录      | `task_id: str`                    | `bool`（删除成功与否）  |

#### 状态文件格式（`state.json`）
```json
{
  "tasks": [
    {
      "task_id": "t123",
      "task_type": "download",
      "status": "completed",  // 状态：pending/running/paused/completed/failed
      "start_time": "2024-10-01 09:00:00",
      "end_time": "2024-10-01 09:30:00",
      "params": {
        "source_type": "huggingface",
        "dataset_name": "lmsys/lmsys-chat-1m",
        "save_dir": "./data/raw/HuggingFace"
      },
      "progress": 100,  // 整体进度（百分比）
      "progress_detail": {
        "downloaded_bytes": 1048576000,
        "total_bytes": 1048576000
      },
      "error_msg": ""  // 失败时记录错误信息，成功时为空
    },
    {
      "task_id": "t202",
      "task_type": "distill",
      "status": "running",
      "start_time": "2024-10-01 10:00:00",
      "end_time": "",
      "params": {
        "source_path": "./data/processed/merged.jsonl",
        "input_field": "question",
        "model_name": "local_vllm"
      },
      "progress": 30,
      "progress_detail": {
        "processed_rows": 300,
        "total_rows": 1000,
        "success_count": 280,
        "failed_count": 20
      },
      "error_msg": ""
    }
  ]
}
```


### 2.4 工具函数模块（`utils.py`）

#### 功能定位
提供跨模块复用的通用工具函数（如文件操作、数据校验、加密解密），避免代码重复，统一处理逻辑。

#### 核心函数分类
1. **文件操作**
   - `read_file_chunk(file_path, chunk_size=1000)`：按行分片读取大文件（支持jsonl/csv/excel/xml）
   - `write_file_chunk(data, file_path, mode="a")`：追加写入分片数据到文件
   - `validate_file_format(file_path, target_format)`：校验文件格式是否符合目标类型（如jsonl格式合法性）
   - `get_file_hash(file_path)`：计算文件哈希值（用于数据校验）

2. **数据处理**
   - `flatten_dict(nested_dict)`：将嵌套字典展平（如XML节点→扁平字段）
   - `filter_empty_rows(data, fields)`：过滤指定字段为空的行数据
   - `dedup_rows(data, field, threshold=0.95)`：基于指定字段去重（支持文本相似度）

3. **加密解密**
   - `encrypt_text(text, key=None)`：加密文本（如API密钥，默认使用配置中的密钥）
   - `decrypt_text(encrypted_text, key=None)`：解密文本
   - `generate_secret_key()`：生成加密用的随机密钥（首次运行时自动生成）

4. **网络与系统**
   - `check_network(url="https://www.baidu.com")`：检查网络连接是否正常
   - `get_free_disk_space(path)`：获取指定路径的剩余磁盘空间（字节）
   - `retry_func(func, args=(), kwargs={}, max_retry=3, delay=2)`：带重试的函数调用（处理临时网络异常）


## 3. 核心功能模块设计

核心功能模块为独立业务模块，每个模块对应一个Python文件，**可单独执行（命令行）或被其他模块调用（函数接口）**，仅依赖基础支撑模块，模块间无直接依赖。


### 3.1 数据集下载模块（`dataset_downloader.py`）
（已实现核心功能，此处补充接口细节）

#### 功能定位
支持从多源（Hugging Face/ModelScope/URL）下载数据集，支持断点续传、并行下载，自动记录下载状态。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `add_download_task(params)` | 创建下载任务并返回task_id         | `params: dict`（含source_type、dataset_name等） | `task_id: str`          |
| `start_task(task_id)`   | 启动指定下载任务                          | `task_id: str`                    | `bool`（启动成功与否）  |
| `pause_task(task_id)`   | 暂停指定下载任务（支持断点续传）          | `task_id: str`                    | `bool`                  |
| `delete_task(task_id)`  | 删除下载任务及临时文件                    | `task_id: str`                    | `bool`                  |


### 3.2 格式转换模块（`format_converter.py`）
（已实现核心功能，此处补充接口细节）

#### 功能定位
支持多种格式（markdown/excel/csv/json/jsonl/xml）的互转，大文件分片处理，确保转换效率和兼容性。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `convert_format(source_path, target_format, output_dir)` | 转换文件格式 | `source_path: str`，`target_format: str`，`output_dir: str` | 转换后文件路径（`str`） |
| `get_supported_formats()` | 获取支持的格式列表                        | 无                                | 格式列表（`list[str]`）  |


### 3.3 字段提取模块（`field_extractor.py`）
（已实现核心功能，此处补充接口细节）

#### 功能定位
从数据集（支持多格式）中提取指定字段（如从混合字段中提取`question`），支持嵌套字段（如XML节点），输出保留指定字段的新数据集。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `get_fields(file_path)` | 自动识别文件中的所有字段（用于UI选择）    | `file_path: str`                  | 字段列表（`list[str]`）  |
| `extract_fields(source_path, fields, output_dir)` | 提取指定字段 | `source_path: str`，`fields: list[str]`，`output_dir: str` | 提取后文件路径（`str`） |


### 3.4 数据合并模块（`data_merger.py`）
（已实现核心功能，此处补充接口细节）

#### 功能定位
合并多个同格式数据集（支持去重），生成合并报告和元数据，支持两种模式：`merge`（合并为新文件）和`append`（追加到现有文件）。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `merge_data(source_paths, mode="merge", output_dir=None, dedup_field=None)` | 合并数据集 | `source_paths: list[str]`，`mode: str`，`output_dir: str`，`dedup_field: str`（去重字段） | 合并后文件路径（`str`） |
| `get_merge_report(task_id)` | 获取合并报告（含行数、去重数）            | `task_id: str`                    | 报告字典（`dict`）      |


### 3.5 模型管理模块（`model_manager.py`）

#### 功能定位
管理所有可用模型（vLLM/OpenAI/SGlang/Ollama），支持模型添加、配置修改、连接测试、状态查询，为蒸馏生成模块提供模型调用能力。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `add_model(model_info)` | 添加新模型配置                            | `model_info: dict`（含name、type、url、api_key等） | `bool`（添加成功与否）  |
| `get_model_config(model_name)` | 获取模型配置（自动解密API密钥）          | `model_name: str`                 | 配置字典（`dict`）      |
| `test_model(model_name)` | 测试模型连接性（发送测试提示词）          | `model_name: str`                 | `dict`（含success、response_time） |
| `get_active_models()`   | 获取所有可用模型（连接测试通过）          | 无                                | 模型列表（`list[dict]`） |
| `delete_model(model_name)` | 删除模型配置                              | `model_name: str`                 | `bool`                  |

#### 模型配置存储格式
模型配置存储在`config.yaml`的`models`节点下：
```yaml
models:
  local_vllm:
    type: "vllm"
    url: "http://localhost:8000/generate"
    api_key: "encrypted:xxx"  # 加密存储
    timeout: 600
  ollama_llama3:
    type: "ollama"
    url: "http://localhost:11434/api/generate"
    api_key: ""  # Ollama无密钥时为空
    timeout: 600
```


### 3.6 蒸馏生成模块（`distill_generator.py`）
（已实现核心功能，此处补充接口细节）

#### 功能定位
基于用户选择的「源数据集字段」和「已配置模型」，自动生成问答对数据集（如用模型回答`question`字段生成`model_answer`字段），支持断点续传、批量调用、失败重试。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `start_distill(params)` | 启动蒸馏任务                              | `params: dict`（含source_path、input_field、model_name等） | `task_id: str`          |
| `pause_distill(task_id)` | 暂停蒸馏任务                              | `task_id: str`                    | `bool`                  |
| `resume_distill(task_id)` | 从断点恢复蒸馏任务                        | `task_id: str`                    | `bool`                  |
| `get_distill_progress(task_id)` | 获取蒸馏进度（含详细统计）                | `task_id: str`                    | 进度字典（见下文格式）  |


### 3.7 数据管理模块（`data_manager.py`）

#### 功能定位
统一管理所有数据集（原始/加工/蒸馏），支持数据预览、关键词搜索、备份/恢复、删除，确保数据可追溯、可复用。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `list_datasets(data_type=None)` | 列出指定类型数据集（raw/processed/distilled） | `data_type: str`（可选）          | 数据集列表（`list[dict]`，含路径、大小、创建时间） |
| `preview_data(file_path, rows=100)` | 预览数据（前N行）                         | `file_path: str`，`rows: int`     | 预览数据（`list[dict]`） |
| `search_data(keyword, fields=None)` | 关键词搜索数据（支持指定字段）            | `keyword: str`，`fields: list[str]`（可选） | 搜索结果（`list[dict]`） |
| `backup_data(file_paths, backup_date=None)` | 备份指定数据集                            | `file_paths: list[str]`，`backup_date: str`（默认当前日期） | 备份路径（`str`）       |
| `restore_data(backup_path, target_dir)` | 从备份恢复数据                            | `backup_path: str`，`target_dir: str` | `bool`（恢复成功与否）  |
| `delete_data(file_path)` | 删除数据集（含元数据）                    | `file_path: str`                  | `bool`                  |

#### 依赖模块
- 基础支撑层：`config_manager.py`（备份目录、预览行数）、`log_manager.py`（日志）、`utils.py`（文件校验、目录操作）
- 第三方库：`pandas`/`jsonlines`（数据预览）、`fnmatch`（路径搜索）


### 3.8 数据清洗模块（`data_cleaner.py`）

#### 功能定位
新增独立模块，支持“去除空值、字段去重、敏感词过滤、内容脱敏”等数据清洗功能，填补数据加工流程中的清洗环节空白。

#### 核心函数接口
| 函数名                  | 功能描述                                  | 输入参数                          | 输出参数                |
|-------------------------|-------------------------------------------|-----------------------------------|-------------------------|
| `start_clean(params)`   | 启动数据清洗任务                          | `params: dict`（见下文参数格式）  | `task_id: str`          |
| `get_clean_progress(task_id)` | 获取清洗进度                              | `task_id: str`                    | 进度字典（含处理行数、清洗统计） |
| `get_clean_report(task_id)` | 获取清洗报告（去空/去重/过滤数量）        | `task_id: str`                    | 报告字典（`dict`）      |

#### 输入参数格式（`params`）
```json
{
  "source_path": "./data/raw/raw_data.jsonl",  // 源文件路径
  "operations": ["remove_empty", "deduplicate", "filter_sensitive", "desensitize"],  // 清洗操作
  "remove_empty_fields": ["question", "answer"],  // 去空字段（remove_empty时必填）
  "dedup_field": "question",  // 去重字段（deduplicate时必填）
  "sensitive_words": ["敏感词1", "敏感词2"],  // 敏感词列表（filter_sensitive时必填）
  "desensitize_fields": {"phone": "hide", "id": "mask"},  // 脱敏字段（desensitize时必填，hide=隐藏/mask=替换）
  "target_format": "jsonl",  // 清洗后目标格式（默认与源一致）
  "output_dir": "./data/processed",  // 输出目录
  "chunk_size": 1000  // 分片大小（默认从配置读取）
}
```

#### 输出文件规范
- 存储路径：`{base.root_dir}/processed/[task_id]/`
- 输出文件：
  - 清洗后文件：`cleaned.[format]`（如`cleaned.jsonl`）
  - 清洗报告：`clean_report.json`（记录去空行数、去重行数、过滤行数）
  - 元数据文件：`meta.json`（记录清洗参数、处理时间）


## 4. 交互层设计

交互层为用户提供「可视化网页操作」和「命令行脚本调用」两种入口，**不实现业务逻辑**，仅通过调用核心功能模块的函数接口完成交互。


### 4.1 网页UI模块（`ui_launcher.py`）

#### 界面结构设计
| 标签页名称 | 核心功能 | 界面组件 | 调用的核心模块函数 |
|------------|----------|----------|-------------------|
| 1. 数据集下载 | 添加/启动/暂停/删除下载任务，配置API密钥 | 源类型选择框（HuggingFace/ModelScope/URL）、数据集名称/URL输入框、API密钥输入框、任务列表表格（含进度条）、操作按钮（启动/暂停/删除） | `dataset_downloader.add_download_task()<br>dataset_downloader.start_task()<br>dataset_downloader.pause_task()` |
| 2. 数据加工 | 格式转换、字段提取、数据合并、数据清洗 | 功能选择标签（转换/提取/合并/清洗）、源文件选择器、参数配置区（如目标格式/字段列表/去重字段）、执行按钮、结果展示区 | `format_converter.convert_format()<br>field_extractor.extract_fields()<br>data_merger.merge_data()<br>data_cleaner.start_clean()` |
| 3. 模型配置 | 添加/编辑/删除模型，测试连接 | 模型列表表格（含类型/状态）、新增模型表单（类型/URL/API密钥）、测试连接按钮、编辑/删除按钮 | `model_manager.add_model()<br>model_manager.test_model()<br>model_manager.get_active_models()` |
| 4. 蒸馏生成 | 启动/暂停/恢复蒸馏任务，查看进度 | 源数据集选择器、输入字段下拉框、提示词编辑框、模型选择框、进度图表（整体进度+详细统计）、操作按钮 | `distill_generator.start_distill()<br>distill_generator.pause_distill()<br>distill_generator.get_distill_progress()` |
| 5. 数据管理 | 数据预览、搜索、备份/恢复、删除 | 数据集列表（按类型分组）、搜索框（支持字段筛选）、预览按钮（弹窗展示）、备份/恢复按钮、删除确认框 | `data_manager.list_datasets()<br>data_manager.preview_data()<br>data_manager.backup_data()<br>data_manager.delete_data()` |

#### 交互逻辑
- **状态同步**：UI定期（每2秒）调用`state_manager.list_tasks()`获取任务状态，更新进度条和按钮状态（如运行中任务显示“暂停”按钮）。
- **参数校验**：所有用户输入通过前端表单校验（如必填项、格式合法性），再传递给核心模块。
- **错误提示**：核心模块返回的错误信息（如文件不存在、模型不可用）通过UI弹窗展示，日志详情可点击查看。


### 4.2 命令行入口（各模块内置）

#### 功能定位
每个核心功能模块均内置`main()`函数，支持通过命令行独立调用，满足开发者自动化脚本需求（如批量任务、定时执行）。

#### 通用调用规范
- 命令格式：`python [模块名].py [参数]`
- 参数传递：支持短参数（`-h`）和长参数（`--help`），`--help`可查看所有参数说明。

#### 各模块命令示例
1. **数据集下载模块**
```bash
# 新增Hugging Face下载任务
python dataset_downloader.py \
  --action add \
  --source_type huggingface \
  --dataset_name lmsys/lmsys-chat-1m \
  --save_dir ./data/raw

# 启动任务
python dataset_downloader.py \
  --action start \
  --task_id t123
```

2. **数据清洗模块**
```bash
# 启动清洗任务（去空+去重+敏感词过滤）
python data_cleaner.py \
  --source_path ./data/raw/raw.jsonl \
  --operations remove_empty deduplicate filter_sensitive \
  --remove_empty_fields question answer \
  --dedup_field question \
  --sensitive_words "敏感词1" "敏感词2" \
  --output_dir ./data/processed
```

3. **数据管理模块**
```bash
# 备份指定数据集
python data_manager.py \
  --action backup \
  --file_paths ./data/processed/cleaned.jsonl ./data/distilled/t202/distilled.jsonl \
  --backup_date 20241001

# 搜索含关键词的数据集
python data_manager.py \
  --action search \
  --keyword "机器学习" \
  --fields question
```


## 5. 数据存储层设计

### 5.1 统一目录结构
所有模块生成的数据严格遵循以下目录结构，确保数据可追溯：
```
./data/  # 根目录（对应config.base.root_dir）
├── raw/                 # 原始数据集（下载模块生成）
│   ├── HuggingFace/     # 按源类型分类
│   │   ├── lmsys-chat-1m/  # 数据集名称
│   │   │   ├── data.jsonl  # 数据文件
│   │   │   └── meta.json   # 元数据（下载时间、来源等）
│   ├── ModelScope/
│   └── URL/
├── processed/           # 加工后数据（转换/提取/合并/清洗生成）
│   ├── t301/            # 任务ID（格式转换任务）
│   │   ├── converted.csv
│   │   └── meta.json
│   ├── t402/            # 任务ID（数据清洗任务）
│   │   ├── cleaned.jsonl
│   │   ├── clean_report.json
│   │   └── meta.json
├── distilled/           # 蒸馏生成数据（蒸馏模块生成）
│   ├── t202/            # 任务ID
│   │   ├── distilled.jsonl
│   │   ├── progress.json
│   │   ├── failed_rows.jsonl
│   │   └── meta.json
├── temp/                # 临时文件（所有模块的中间文件）
│   ├── t123/            # 任务ID（下载临时文件）
│   └── t202/            # 任务ID（蒸馏临时文件）
├── backup/              # 备份数据集（数据管理模块生成）
│   ├── 20241001/        # 备份日期
│   │   ├── raw/         # 按数据类型备份
│   │   ├── processed/
│   │   └── distilled/
├── logs/                # 日志文件（日志模块生成）
│   ├── 20241001/        # 日志日期
│   │   ├── dataset_downloader.log
│   │   ├── format_converter.log
│   │   ├── model_manager.log
│   │   └── distill_generator.log
├── config.yaml          # 全局配置文件（配置模块生成/维护）
└── state.json           # 状态文件（状态模块生成/维护）
```

### 5.2 文件格式规范
1. **元数据文件（`meta.json`）**：所有模块生成数据必须包含，记录数据来源、处理参数、时间等
   ```json
   {
     "task_id": "t202",
     "task_type": "distill",
     "source_path": "./data/processed/merged.jsonl",
     "params": {
       "input_field": "question",
       "model_name": "local_vllm",
       "batch_size": 10
     },
     "start_time": "2024-10-01 10:00:00",
     "end_time": "2024-10-01 11:30:00",
     "row_count": 1000,  # 数据总行数
     "file_size": 2097152  # 文件大小（字节）
   }
   ```

2. **日志文件**：按模块和日期拆分，格式统一（见2.2节）

3. **数据文件**：
   - 文本类：优先使用`jsonl`（每行一个JSON对象），支持流式读写
   - 表格类：`csv`（逗号分隔）、`excel`（.xlsx）
   - 结构化标记：`xml`（根节点为`dataset`，每行数据对应`row`节点）


## 6. 模块调用关系

### 6.1 模块依赖矩阵
| 调用方模块            | 基础支撑层（依赖）                          | 核心功能层（依赖） | 交互层（依赖） |
|-----------------------|---------------------------------------------|--------------------|----------------|
| dataset_downloader.py | config_manager、log_manager、state_manager、utils | 无                 | 无             |
| format_converter.py   | config_manager、log_manager、utils          | 无                 | 无             |
| field_extractor.py    | config_manager、log_manager、utils          | 无                 | 无             |
| data_merger.py        | config_manager、log_manager、utils          | 无                 | 无             |
| model_manager.py      | config_manager、log_manager、utils          | 无                 | 无             |
| distill_generator.py  | config_manager、log_manager、state_manager、utils | model_manager      | 无             |
| data_manager.py       | config_manager、log_manager、utils          | 无                 | 无             |
| data_cleaner.py       | config_manager、log_manager、state_manager、utils | 无                 | 无             |
| ui_launcher.py        | config_manager、log_manager、state_manager  | 所有核心功能模块   | 无             |


### 6.2 核心流程调用示例
以「从Hugging Face下载→数据清洗→格式转换→字段提取→蒸馏生成」全流程为例：

1. **下载数据集**：
   - `ui_launcher.py` → `dataset_downloader.add_download_task()`（创建任务）
   - `dataset_downloader.start_task()` → 调用`utils.retry_func()`（断点续传）、`state_manager.update_state()`（更新进度）

2. **数据清洗**：
   - `ui_launcher.py` → `data_cleaner.start_clean()`（传入下载的原始数据路径）
   - `data_cleaner.py` → 调用`utils.read_file_chunk()`（分片读取）、`utils.filter_empty_rows()`（去空）、`state_manager.update_state()`（更新进度）

3. **格式转换**：
   - `ui_launcher.py` → `format_converter.convert_format()`（清洗后数据→jsonl）
   - `format_converter.py` → 调用`utils.validate_file_format()`（格式校验）、`log_manager.get_logger()`（记录转换日志）

4. **字段提取**：
   - `ui_launcher.py` → `field_extractor.extract_fields()`（提取`question`字段）
   - `field_extractor.py` → 调用`utils.read_file_chunk()`（读取转换后的数据）

5. **蒸馏生成**：
   - `ui_launcher.py` → 调用`model_manager.get_active_models()`（获取可用模型）
   - 调用`distill_generator.start_distill()`（传入提取的`question`字段数据）
   - `distill_generator.py` → 调用`model_manager.get_model_config()`（获取模型配置）、`state_manager.update_state()`（实时更新进度）


## 7. 配置与日志规范

### 7.1 配置规范
- **配置粒度**：按模块划分配置项（如`download`/`distill`），避免全局混杂
- **敏感配置**：API密钥等敏感信息必须通过`config_manager.encrypt_config()`加密存储
- **默认值**：所有配置项必须有合理默认值，确保首次运行无需手动配置
- **动态更新**：支持运行时通过`config_manager.update_config()`更新配置，无需重启

### 7.2 日志规范
- **分级标准**：
  - `DEBUG`：开发调试信息（如函数参数、中间结果），默认不开启
  - `INFO`：正常流程信息（如任务启动、进度更新）
  - `WARN`：非致命异常（如重试、性能警告）
  - `ERROR`：致命错误（如文件损坏、模型离线）
- **日志内容**：必须包含时间、模块名、级别、消息，关键操作需记录`task_id`
- **隐私保护**：日志中禁止包含明文API密钥、敏感数据内容


## 8. 异常处理规范

### 8.1 异常类型定义
| 异常类名               | 触发场景                                  | 处理策略                          |
|------------------------|-------------------------------------------|-----------------------------------|
| `FileFormatError`      | 文件格式非法（如JSON解析失败）            | 记录ERROR日志，返回具体错误位置    |
| `NetworkError`         | 网络连接异常（如下载超时、模型API不可达） | 自动重试（最多`retry_count`次）   |
| `ModelUnavailableError` | 模型连接测试失败                          | 标记模型为不可用，提示用户检查配置 |
| `TaskConflictError`    | 任务状态冲突（如暂停已完成任务）          | 忽略操作，返回友好提示            |
| `ResourceLimitError`   | 资源超限（如磁盘满、并行任务超上限）      | 暂停任务，等待资源释放            |

### 8.2 异常处理流程
1. 核心模块捕获异常后，首先通过`log_manager`记录ERROR级日志（含堆栈信息）
2. 调用`state_manager.update_state()`更新任务状态为`failed`，并记录`error_msg`
3. 若为交互层调用，将`error_msg`返回给UI/命令行，展示给用户
4. 可恢复异常（如`NetworkError`）自动重试，超过重试次数则标记任务失败


## 9. 扩展性设计

### 9.1 新增数据格式支持（以XML为例）
#### 扩展步骤
1. **工具函数扩展（`utils.py`）**：
   - 新增`read_xml(file_path, chunk_size=1000)`：分片读取XML，解析为字典列表
   - 新增`write_xml(data, file_path, root_tag="dataset", item_tag="row")`：写入XML
   - 新增`validate_xml_format(file_path)`：校验XML合法性

2. **格式转换模块扩展（`format_converter.py`）**：
   - 在`SUPPORTED_FORMATS`添加`"xml"`，更新`FORMAT_EXTENSIONS`（`xml: [".xml"]`）
   - 新增`_convert_from_xml()`和`_convert_to_xml()`转换函数

3. **其他模块适配**：
   - `field_extractor.py`：更新`get_fields()`支持XML节点识别
   - `data_merger.py`：支持XML文件合并（调用`utils.read_xml()`和`utils.write_xml()`）

#### 扩展影响
- 无现有代码修改，仅新增函数和配置，兼容原有功能
- 所有依赖格式处理的模块（如数据合并、数据管理）自动支持XML


### 9.2 新增模型类型支持（以Ollama为例）
#### 扩展步骤
1. **模型管理模块扩展（`model_manager.py`）**：
   - 在`SUPPORTED_TYPES`添加`"ollama"`
   - 新增`_validate_ollama_config()`：校验Ollama配置（URL格式等）
   - 新增`_test_ollama_connection()`：测试Ollama连接（发送`llama3:8b`测试请求）

2. **蒸馏生成模块扩展（`distill_generator.py`）**：
   - 新增`_call_ollama_api()`：实现Ollama API调用逻辑（兼容批量请求）
   - 在`_call_model_api()`中添加类型判断，路由到`_call_ollama_api()`

#### 扩展影响
- 仅修改`model_manager.py`和`distill_generator.py`，不影响现有模型
- 用户可在UI中直接选择Ollama模型启动蒸馏任务


### 9.3 新增功能模块（如数据增强模块`data_augmenter.py`）
#### 扩展步骤
1. **模块设计**：
   - 功能：基于原始文本生成同义句、扩展问答对（如反问、解释）
   - 核心函数：`start_augment(params)`、`get_augment_progress(task_id)`
   - 依赖：基础支撑层（`config_manager`/`log_manager`等）、`model_manager`（调用模型生成增强数据）

2. **交互层集成**：
   - 在`ui_launcher.py`新增“数据增强”标签页，添加参数配置组件
   - 命令行入口：实现`main()`函数，支持参数调用

3. **存储规范**：
   - 输出路径：`{base.root_dir}/processed/[task_id]/`
   - 输出文件：`augmented.[format]`、`augment_report.json`、`meta.json`

#### 扩展影响
- 新增独立模块，不修改现有代码
- 可无缝集成到现有流程（如清洗→增强→蒸馏）


## 10. 总结

### 10.1 设计核心优势
1. **模块化低耦合**：所有模块独立成Python文件，通过标准化接口交互，可单独开发、测试、复用（如`dataset_downloader.py`可单独用于数据集下载）。
2. **双交互模式兼容**：网页UI满足非技术用户需求，命令行支持开发者自动化脚本，两种模式共享核心逻辑，确保结果一致。
3. **可靠性保障**：通过断点续传（状态管理）、异常重试、数据校验、自动备份，确保大规模数据和长时间任务的稳定性。
4. **高扩展性**：新增格式、模型、功能时仅需在对应模块新增代码，无需重构现有逻辑。
5. **可追溯性**：统一目录结构、元数据文件、关联日志，确保数据全链路可追溯。


### 10.2 实施路径
1. **阶段1：基础支撑层开发（1-2天）**
   - 实现`config_manager.py`、`log_manager.py`、`state_manager.py`、`utils.py`
   - 编写基础测试脚本，验证配置读写、日志记录、状态恢复功能

2. **阶段2：核心功能层开发（3-5天）**
   - 优先开发：`dataset_downloader.py`→`format_converter.py`→`model_manager.py`→`distill_generator.py`
   - 补充开发：`data_merger.py`→`field_extractor.py`→`data_manager.py`→`data_cleaner.py`
   - 每个模块开发后，编写独立测试脚本（如`test_distill_generator.py`）

3. **阶段3：交互层开发（1-2天）**
   - 开发`ui_launcher.py`，实现5个标签页，对接核心模块接口
   - 测试UI与核心模块联动（如UI启动任务→状态同步到界面）

4. **阶段4：全流程测试与优化（1-2天）**
   - 执行全流程测试：下载→清洗→转换→提取→蒸馏→备份
   - 优化异常处理和UI体验，编写用户手册


### 10.3 后续迭代方向
1. **新增数据源**：支持本地文件夹导入、数据库（MySQL/PostgreSQL）读取，扩展`dataset_downloader.py`。
2. **模型增强**：支持模型微调（基于蒸馏数据集微调小模型），新增`model_finetune.py`。
3. **分布式支持**：针对超大规模数据集，支持分布式下载、蒸馏，通过`config.yaml`配置节点。
4. **API服务化**：封装核心功能为REST API（如`/api/download`/`/api/distill`），新增`api_server.py`。

通过以上设计，可构建完整、可靠、易用的自动数据蒸馏软件，满足从数据获取到模型训练的数据支撑需求，同时兼顾灵活性和扩展性。